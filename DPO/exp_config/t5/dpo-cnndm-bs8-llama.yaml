exp_name: t5
trainer:
  run_name: 'dpo-1'
  output_dir: '/data/gaolr/workspace/DPO-ST/ft_models/t5-cnndm-llama/dpo-train0-39_dev0-999_concat_bs8-10000-bs8-weak'
  overwrite_output_dir: true
  bf16: true
  tf32: true
  report_to: 'wandb'
  seed: 42
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 8
  per_device_eval_batch_size: 1
  max_steps: 10000
  optim: 'adamw_torch'
  weight_decay: 0.01
  lr_scheduler_type: 'cosine_with_min_lr'
  learning_rate: 7e-7
  lr_scheduler_kwargs:
    min_lr_rate: 0.1
  warmup_ratio: 0.1
  save_strategy: 'steps'
  ddp_find_unused_parameters: false
  dataloader_num_workers: 12
  beta: 0.1
  max_prompt_length: 2200
  max_target_length: 150
  max_length: 2350
  eval_strategy: 'steps'
  eval_steps: 100
  save_steps: 100
  save_safetensors: False
  logging_steps: 10
  remove_unused_columns: False

model:
  sft_run_name: sft-0
  model_path: out/SFT-input+weak2prompt

data:
  data_dir: model_outputs/${exp_name}/${model.sft_run_name}/train/
  data_path: ''
  train_data_path: ''
  dev_data_path: ''
  test_data_path: ''
  tokenizer_path: ${model.model_path}
  model_max_length: 2350
  max_src_len: 2200
  max_tgt_len: 150

eval:
  per_device_eval_batch_size: 24
  max_new_tokens: 2350
  use_calc: true
  mode: 'greedy'
  sampling:
    temperature: 0.7
    min_seed: 0
    max_seed: 10